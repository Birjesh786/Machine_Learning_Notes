
# Feature Engeeniring in Machine Learning

Feature engineering is the process of selecting, manipulating, and transforming raw data into features that can be used in supervised learning. In order to make machine learning work well on new tasks, it might be necessary to design and train better features. As you may know, a “feature” is any measurable input that can be used in a predictive model — it could be the color of an object or the sound of someone’s voice. Feature engineering, in simple terms, is the act of converting raw observations into desired features using statistical or machine learning approaches.


## Topic's in Feature Engineering
## 1. Standardization

## 2. Normalization

## 3. Transformer

    3.1 Column Transformer

    3.2 Power Transformer
    
    3.3 Function Transformer

## 4. Encoding

    4.1 Ordinal Encoding

    4.2 One-Hot Encoding

## 5. Pipelines

## 6. Handling Mixed Variables

    6.1 Mixed Variables

    6.2 Date and Time Variables

## 7. Handling Missing Data

    7.1 CCA (Complete Case Analysis)

    7.2 Numeric and Categorical Data with simple and most frequent imputer

    7.3 Random Sample Imputation

    7.4 KNN or Multivariate Imputer

## 8. MICE (Multivariate imputation with chain equation

## 9. Outliers

## 10. Outliers Detection Method

    10.1 With Z-Score

    10.2 With IQR

    10.3 With Percentile

    10.4 With Winsorization

## 11. Feature Construction

## 12. Feature Splitting

## 13. (COD) Curse of Dimensionality

## 14. (PCA) Principal Component Analysis




